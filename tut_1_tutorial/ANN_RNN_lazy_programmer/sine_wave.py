# -*- coding: utf-8 -*-
"""Sine Wave.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sJbkiPvkoY6P95iEghzJsGAmQ_0v5fwn
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error as mae

from keras.models import Model
from keras.layers import Input, LSTM, GRU, SimpleRNN, Dense
import keras.backend as K

from keras.optimizers import SGD, Adam

# make the original data
series = np.sin(0.1*np.arange(200)) + np.random.randn(200)*0.1

# plot it
plt.plot(series)
plt.show()

### build the dataset
# let's see if we can use T past values to predict the next value
T = 10
D = 1
X = []
Y = []
for t in range(len(series) - T):
  x = series[t:t+T]
  X.append(x)
  y = series[t+T]
  Y.append(y)

X = np.array(X)
Y = np.array(Y)
N = len(X)

# split into train and test
Xtrain, Ytrain = X[:-N//2], Y[:-N//2]
Xtest, Ytest = X[-N//2:], Y[-N//2:]

### try autoregressive model
model = LinearRegression()
model.fit(Xtrain, Ytrain)

# get model predictions
Ptrain = model.predict(Xtrain)
Ptest = model.predict(Xtest)

# print R^2
print("linear train r^2:", model.score(Xtrain, Ytrain))
print("linear test r^2:", model.score(Xtest, Ytest))

# print MAE
print("linear train mae:", mae(Ytrain, Ptrain))
print("linear test mae:", mae(Ytest, Ptest))

# One-Step Forecast
plt.plot(Ptest, label='predictions')
plt.plot(Ytest, label='targets')
plt.title("Linear Regression One-Step Forecast")
plt.legend()
plt.show()

# Real forecast
forecast = []
input_ = Xtest[0]
while len(forecast) < len(Ytest):
  x = np.expand_dims(input_, 0)
  f = model.predict(x)
  forecast.append(f[0])
  # make a new input with the latest forecast
  input_ = np.concatenate([input_[1:], f])

plt.plot(forecast, label='forecast')
plt.plot(Ytest, label='targets')
plt.title("Linear Regression Forecast")
plt.legend()
plt.show()

# Make inputs N x T x D
inputs_train = Xtrain.reshape(-1, T, 1)
inputs_test = Xtest.reshape(-1, T, 1)

# make the RNN
i = Input(shape=(T, D))
x = SimpleRNN(5)(i)
x = Dense(1)(x)
model = Model(i, x)
model.compile(
  loss='mse',
  optimizer=Adam(lr=0.1),
)

# train the RNN
r = model.fit(
  inputs_train, Ytrain,
  batch_size=32,
  epochs=80,
  validation_data=(inputs_test, Ytest),
)

# plot loss per iteration
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()
plt.show()

# Get flattened predictions
Ptrain = model.predict(inputs_train).flatten()
Ptest = model.predict(inputs_test).flatten()

print("RNN_doc train mae:", mae(Ytrain, Ptrain))
print("RNN_doc test mae:", mae(Ytest, Ptest))

# plot predictions vs targets
plt.plot(Ytest, label='targets')
plt.plot(Ptest, label='predictions')
plt.title("RNN One-Step Forecast")
plt.legend()
plt.show()

# Real forecast
forecast = []
input_ = Xtest[0]
while len(forecast) < len(Ytest):
  f = model.predict(input_.reshape(1, T, 1))[0,0]
  forecast.append(f)

  # make a new input with the latest forecast
  input_ = np.roll(input_, -1)
  input_[-1] = f

plt.plot(forecast, label='forecast')
plt.plot(Ytest, label='targets')
plt.title("RNN Forecast")
plt.legend()
plt.show()

